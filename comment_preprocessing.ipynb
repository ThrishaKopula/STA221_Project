{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13f7312-5f04-427f-96d5-29d86e21e42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_content</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_utc</th>\n",
       "      <th>RoBERTa_sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js0zukm</td>\n",
       "      <td>Did you get a second opinion?</td>\n",
       "      <td>6894</td>\n",
       "      <td>2023-07-15 04:18:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js1079r</td>\n",
       "      <td>On purpose?</td>\n",
       "      <td>15404</td>\n",
       "      <td>2023-07-15 04:21:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.710324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js1269h</td>\n",
       "      <td>\"Why does this keep happening to me?! Second t...</td>\n",
       "      <td>11788</td>\n",
       "      <td>2023-07-15 04:41:47</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.935446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js11llk</td>\n",
       "      <td>“Is it yours?”</td>\n",
       "      <td>24645</td>\n",
       "      <td>2023-07-15 04:35:52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js0yusy</td>\n",
       "      <td>Congrats! Whose is it?</td>\n",
       "      <td>8216</td>\n",
       "      <td>2023-07-15 04:07:51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id                                    comment_content  \\\n",
       "0  1501ibb    js0zukm                      Did you get a second opinion?   \n",
       "1  1501ibb    js1079r                                        On purpose?   \n",
       "2  1501ibb    js1269h  \"Why does this keep happening to me?! Second t...   \n",
       "3  1501ibb    js11llk                                     “Is it yours?”   \n",
       "4  1501ibb    js0yusy                             Congrats! Whose is it?   \n",
       "\n",
       "   comment_score  comment_created_utc  RoBERTa_sentiment  sentiment_score  \n",
       "0           6894  2023-07-15 04:18:00                  0         0.924712  \n",
       "1          15404  2023-07-15 04:21:36                  0         0.710324  \n",
       "2          11788  2023-07-15 04:41:47                 -1         0.935446  \n",
       "3          24645  2023-07-15 04:35:52                  0         0.920336  \n",
       "4           8216  2023-07-15 04:07:51                  1         0.966621  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Basis Libraries    \n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/ffnn.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591459bb-ef66-432e-9f92-d36863cf68e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_content</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_utc</th>\n",
       "      <th>RoBERTa_sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js0zukm</td>\n",
       "      <td>did you get a second opinion?</td>\n",
       "      <td>6894</td>\n",
       "      <td>2023-07-15 04:18:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js1079r</td>\n",
       "      <td>on purpose?</td>\n",
       "      <td>15404</td>\n",
       "      <td>2023-07-15 04:21:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.710324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js1269h</td>\n",
       "      <td>\"why does this keep happening to me?! second t...</td>\n",
       "      <td>11788</td>\n",
       "      <td>2023-07-15 04:41:47</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.935446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js11llk</td>\n",
       "      <td>“is it yours?”</td>\n",
       "      <td>24645</td>\n",
       "      <td>2023-07-15 04:35:52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js0yusy</td>\n",
       "      <td>congrats! whose is it?</td>\n",
       "      <td>8216</td>\n",
       "      <td>2023-07-15 04:07:51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id                                    comment_content  \\\n",
       "0  1501ibb    js0zukm                      did you get a second opinion?   \n",
       "1  1501ibb    js1079r                                        on purpose?   \n",
       "2  1501ibb    js1269h  \"why does this keep happening to me?! second t...   \n",
       "3  1501ibb    js11llk                                     “is it yours?”   \n",
       "4  1501ibb    js0yusy                             congrats! whose is it?   \n",
       "\n",
       "   comment_score  comment_created_utc  RoBERTa_sentiment  sentiment_score  \n",
       "0           6894  2023-07-15 04:18:00                  0         0.924712  \n",
       "1          15404  2023-07-15 04:21:36                  0         0.710324  \n",
       "2          11788  2023-07-15 04:41:47                 -1         0.935446  \n",
       "3          24645  2023-07-15 04:35:52                  0         0.920336  \n",
       "4           8216  2023-07-15 04:07:51                  1         0.966621  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_content'] = df['comment_content'].astype(str)\n",
    "df['comment_content'] = df['comment_content'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11eacd37-aa99-4200-b2b0-0c2b14d6cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Regular Expression\n",
    "import re\n",
    "\n",
    "# Function to remove HTML Tags\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b17e8d9e-1783-47dd-b791-ff0524611148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba01e3be-d84f-4ccc-8990-108fc3f30c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77e6d2ce-d844-417c-8703-f7c476f62bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5df05ad-5d74-4c33-9511-511db58b840c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80c7d6cb-6deb-4c1b-a667-c97f12a54059",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('', '', punc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0e40f6e-a410-466b-adb0-0569d8331307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8b1a31f-914b-48ad-abdf-49cfec6f44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository Link : https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt\n",
    "chat_words = {\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"B4\": \"Before\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GR8\": \"Great!\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
    "    \"ILU\": \"ILU: I Love You\",\n",
    "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMAO\": \"Laugh My A.. Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"PITA\": \"Pain In The A..\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"QPSA?\": \"Que Pasa?\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your sex and age\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TTFN\": \"Ta-Ta For Now!\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The F...\",\n",
    "    \"WTG\": \"Way To Go!\",\n",
    "    \"WUF\": \"Where Are You From?\",\n",
    "    \"W8\": \"Wait...\",\n",
    "    \"7K\": \"Sick:-D Laugher\",\n",
    "    \"TFW\": \"That feeling when\",\n",
    "    \"MFW\": \"My face when\",\n",
    "    \"MRW\": \"My reaction when\",\n",
    "    \"IFYP\": \"I feel your pain\",\n",
    "    \"TNTL\": \"Trying not to laugh\",\n",
    "    \"JK\": \"Just kidding\",\n",
    "    \"IDC\": \"I don't care\",\n",
    "    \"ILY\": \"I love you\",\n",
    "    \"IMU\": \"I miss you\",\n",
    "    \"ADIH\": \"Another day in hell\",\n",
    "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
    "    \"WYWH\": \"Wish you were here\",\n",
    "    \"TIME\": \"Tears in my eyes\",\n",
    "    \"BAE\": \"Before anyone else\",\n",
    "    \"FIMH\": \"Forever in my heart\",\n",
    "    \"BSAAW\": \"Big smile and a wink\",\n",
    "    \"BWL\": \"Bursting with laughter\",\n",
    "    \"BFF\": \"Best friends forever\",\n",
    "    \"CSL\": \"Can't stop laughing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92cbac69-491f-43ee-8abf-d19bc2b7b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for i in text.split():\n",
    "        if i.upper() in chat_words:\n",
    "            new_text.append(chat_words[i.upper()])\n",
    "        else:\n",
    "            new_text.append(i)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9678659-4907-43b8-9828-0ee9be914a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(chat_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8b78a67-0c82-46f5-8c0e-c29b33b347dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42871f97-d2a1-4193-b42e-10c3e924c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aff3990b-4455-4c64-af14-2adc0df1b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stopword:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bb8081f-2784-4a82-8fbb-b0b9cd5a0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ff06c99-4905-49dd-b42d-bb1f40f5e892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6b0c024-c5ef-42a9-a6b6-08ee08b1ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_emoji(text):\n",
    "    return emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b79c5a71-7276-493b-aec5-88a02ca9d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(conv_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54fef598-577c-4614-b9bd-85415e87a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraray \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f61c8b6-0d38-4f57-a841-e6002ffbf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_word(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5764d7f0-2af6-4750-be5a-014676ba9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(tok_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05d3b8d0-6eef-4055-a2ad-7235ba2c757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['comment_content'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0101be19-e9e2-4e91-a7fe-de88139df0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3c2067e-86b9-4a39-b0f5-4b24ef008f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# This Function Will Stem Words\n",
    "def stem_words(text_list):\n",
    "    return [\" \".join([stemmer.stem(word) for word in text.split()]) for text in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9aab246-728a-449f-b2ad-7546f25af1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81211ec0-c666-4a49-9e0d-1ed1bd42cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "76d967e4-aa0f-4052-b83e-b87be0266ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):  # Adjective\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):  # Verb\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):  # Noun\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):  # Adverb\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun if unknown\n",
    "\n",
    "# Function to lemmatize a list of strings with all POS considered\n",
    "def lemmatize_text_list(text_list):\n",
    "    lemmatized_list = []\n",
    "    for text in text_list:\n",
    "        tokens = nltk.word_tokenize(text)  # Tokenize the text\n",
    "        pos_tags = nltk.pos_tag(tokens)  # Get POS tags\n",
    "        lemmatized_sentence = \" \".join(\n",
    "            [wordnet_lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "        )\n",
    "        lemmatized_list.append(lemmatized_sentence)\n",
    "    return lemmatized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "29d19741-e710-46f3-8e53-882ef149c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_content'] = df['comment_content'].apply(lemmatize_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9bb41d7-bb5a-43c6-b92a-2bdeba78b50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_content</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created_utc</th>\n",
       "      <th>RoBERTa_sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js0zukm</td>\n",
       "      <td>[get, second, opinion]</td>\n",
       "      <td>6894</td>\n",
       "      <td>2023-07-15 04:18:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js1079r</td>\n",
       "      <td>[purpos]</td>\n",
       "      <td>15404</td>\n",
       "      <td>2023-07-15 04:21:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.710324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js1269h</td>\n",
       "      <td>[keep, happen, second, tear, eye, week]</td>\n",
       "      <td>11788</td>\n",
       "      <td>2023-07-15 04:41:47</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.935446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js11llk</td>\n",
       "      <td>[“, be, your, ”]</td>\n",
       "      <td>24645</td>\n",
       "      <td>2023-07-15 04:35:52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1501ibb</td>\n",
       "      <td>js0yusy</td>\n",
       "      <td>[congrat, whose]</td>\n",
       "      <td>8216</td>\n",
       "      <td>2023-07-15 04:07:51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id                          comment_content  comment_score  \\\n",
       "0  1501ibb    js0zukm                   [get, second, opinion]           6894   \n",
       "1  1501ibb    js1079r                                 [purpos]          15404   \n",
       "2  1501ibb    js1269h  [keep, happen, second, tear, eye, week]          11788   \n",
       "3  1501ibb    js11llk                         [“, be, your, ”]          24645   \n",
       "4  1501ibb    js0yusy                         [congrat, whose]           8216   \n",
       "\n",
       "   comment_created_utc  RoBERTa_sentiment  sentiment_score  \n",
       "0  2023-07-15 04:18:00                  0         0.924712  \n",
       "1  2023-07-15 04:21:36                  0         0.710324  \n",
       "2  2023-07-15 04:41:47                 -1         0.935446  \n",
       "3  2023-07-15 04:35:52                  0         0.920336  \n",
       "4  2023-07-15 04:07:51                  1         0.966621  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86dca30d-5a94-40ae-a89a-640223f57fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/comment_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60170d8f-4551-479a-b93f-e4a30d96dccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
